# emotion1
1. Project Description
This project aims to address the challenge of data imbalance in multimodal emotion recognition from real-time and pre-recorded videos using Convolutional Neural Networks (CNNs). It combines facial expression analysis and audio cues to classify emotional states (e.g., happy, sad, angry, neutral). The focus is on improving model performance by applying data balancing techniques, such as oversampling, class weighting, and augmentation, to enhance fairness and accuracy.

 2. System Overview
Input: Real-time webcam feed or pre-recorded video files
Preprocessing:
Face and audio extraction
Feature normalization
Data balancing
Model: CNN-based architecture for emotion classification
Output: Detected emotion with confidence score

Addressing Data Imbalance in Multimodal Conversational Emotion Analysis Using CNN (Real-Time and Pre-recorded Videos)

Description
This project classifies human emotions using facial expressions and audio features from real-time and pre-recorded videos. It applies CNN models and solves class imbalance issues to improve accuracy and fairness.

 Requirements
- Python 3.10
- OpenCV
- TensorFlow / Keras
- NumPy
- librosa

Install dependencies:
```bash
pip install -r requirements.txt


